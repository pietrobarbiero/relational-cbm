{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3eeeb22d241069",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Relational Concept Bottleneck Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26912dbf82dcbc8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First of all we need to create a dataset. For this we will use a standard dataset used for graph neural networks, the Cora dataset. The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a63707f3c5182b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We first pre-train a graph neural network model on the Cora dataset. We will use the PyTorch Geometric library to load the dataset and create the model. The model is a Graph Convolutional Network (GCN) trained using the standard cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18aa453c-11b3-4adf-aba6-3ca8d7decfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecf38b690f26439",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.gnn_benchmarks import gnn_benchmark_dataset\n",
    "_, (train_data, queries_train), _, (test_data, queries_test), num_classes, manifold_ids = gnn_benchmark_dataset('CORA', perc_train=1.0, pretrain_seed = 0)\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4634311-2e70-4266-83a8-4ea43b374bdb",
   "metadata": {},
   "source": [
    "We inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5370c8-5eb7-4a17-8d23-1d3f2002a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2708, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.6401],\n",
       "         [3.2565, 0.0000, 0.0000,  ..., 0.9476, 3.2784, 2.2935],\n",
       "         [2.0837, 0.0000, 0.0000,  ..., 0.4678, 2.2164, 2.2745],\n",
       "         ...,\n",
       "         [1.7258, 0.0000, 2.4617,  ..., 0.7127, 1.5019, 0.6909],\n",
       "         [0.0000, 0.2022, 0.0000,  ..., 0.0000, 0.0000, 2.0309],\n",
       "         [0.0000, 0.2505, 0.0000,  ..., 0.0309, 0.0000, 1.7998]]],\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are input features\n",
    "print(train_data.tensors[0].shape)\n",
    "train_data.tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de9ef59b-d2cc-4f4e-b878-c231617e5155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 980])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are concept labels to predict\n",
    "print(train_data.tensors[1].shape)\n",
    "train_data.tensors[1][0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24175d66-bcc3-4b2f-945b-15ef845d2fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 980])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are class labels to predict (same as concept labels!)\n",
    "print(train_data.tensors[2].shape)\n",
    "train_data.tensors[1][0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92baca0f-42b3-4e59-a6ca-85cbf3c426f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '633'],\n",
       "       ['0', '1862'],\n",
       "       ['0', '2582'],\n",
       "       ...,\n",
       "       ['2707', '598'],\n",
       "       ['2707', '1473'],\n",
       "       ['2707', '2706']], dtype='<U21')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are connections in the citation graph (e.g., \"paper 0 cites paper 633\")\n",
    "manifold_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce16fe-2825-4c05-a303-05e7eb581c85",
   "metadata": {},
   "source": [
    "Create a domain of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e632e1ab-f017-481a-947d-fbdb24412a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constants: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rcbm.logic.commons import Domain\n",
    "n_samples = train_data.tensors[0].shape[1]\n",
    "n_features = train_data.tensors[0].shape[2]\n",
    "documents = Domain(\"documents\", [f'{i}' for i in torch.arange(n_features).tolist()])\n",
    "print(f'Number of constants: {len(documents.constants)}')\n",
    "documents.constants[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85798d5d-7b33-458a-85c5-a65ad8523c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class0', 'X'),\n",
       " ('class1', 'X'),\n",
       " ('class2', 'X'),\n",
       " ('class3', 'X'),\n",
       " ('class4', 'X'),\n",
       " ('class5', 'X'),\n",
       " ('class6', 'X'),\n",
       " ('class0', 'Y'),\n",
       " ('class1', 'Y'),\n",
       " ('class2', 'Y'),\n",
       " ('class3', 'Y'),\n",
       " ('class4', 'Y'),\n",
       " ('class5', 'Y'),\n",
       " ('class6', 'Y')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rcbm.logic.commons import Rule\n",
    "body = ['class%d(X)' % c for c in range(num_classes)]\n",
    "head = ['class%d(Y)' % c for c in range(num_classes)]\n",
    "rule = Rule(\"phi\", body=body+head, head=head, var2domain={\"X\": \"documents\", \"Y\": \"documents\"})\n",
    "rule.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "86075f03-8f48-4ff0-8e21-10ac9ebac40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class0', 'Y'),\n",
       " ('class1', 'Y'),\n",
       " ('class2', 'Y'),\n",
       " ('class3', 'Y'),\n",
       " ('class4', 'Y'),\n",
       " ('class5', 'Y'),\n",
       " ('class6', 'Y')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90765da0-547f-4071-8739-a98e4206758d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mutex: ('class0', 'X'),('class1', 'X'),('class2', 'X'),('class3', 'X'),('class4', 'X'),('class5', 'X'),('class6', 'X') -> "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule2 = Rule(\"mutex\", body=body, head=[], var2domain={\"X\": \"documents\"})\n",
    "rule2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "61b0ca26-3259-44fb-97d9-f2c9497d2f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('class0', '65'),\n",
       "  ('class1', '65'),\n",
       "  ('class2', '65'),\n",
       "  ('class3', '65'),\n",
       "  ('class4', '65'),\n",
       "  ('class5', '65'),\n",
       "  ('class6', '65')),\n",
       " (('class0', '239'),\n",
       "  ('class1', '239'),\n",
       "  ('class2', '239'),\n",
       "  ('class3', '239'),\n",
       "  ('class4', '239'),\n",
       "  ('class5', '239'),\n",
       "  ('class6', '239'),\n",
       "  ('class0', '65'),\n",
       "  ('class1', '65'),\n",
       "  ('class2', '65'),\n",
       "  ('class3', '65'),\n",
       "  ('class4', '65'),\n",
       "  ('class5', '65'),\n",
       "  ('class6', '65')))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rcbm.logic.grounding import DomainGrounder\n",
    "grounder = DomainGrounder({\"documents\": documents.constants}, [rule, rule2], manifolds_per_rule={\"phi\": manifold_ids})\n",
    "groundings = grounder.ground()\n",
    "groundings['phi'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24944d60-e16f-43d6-afb4-f84601f25b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((),\n",
       " (('class0', '0'),\n",
       "  ('class1', '0'),\n",
       "  ('class2', '0'),\n",
       "  ('class3', '0'),\n",
       "  ('class4', '0'),\n",
       "  ('class5', '0'),\n",
       "  ('class6', '0')))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundings['mutex'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "28cbdcef-8694-4baf-b890-0bb85e6f632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcbm.logic.indexing import DictBasedIndexer\n",
    "from rcbm.logic.semantics import ProductTNorm\n",
    "logic = ProductTNorm()\n",
    "indexer = DictBasedIndexer(groundings, {\"tasks\": queries_train, \"concepts\": queries_train}, logic=logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4a7759dd-1d2b-474f-9642-ad375cd3d009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=7, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 16\n",
    "n_concepts = len(rule.body)\n",
    "n_classes = len(rule.head)\n",
    "\n",
    "encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_features, emb_size),\n",
    "    torch.nn.LeakyReLU(),\n",
    ")\n",
    "relation_classifiers = {}\n",
    "for relation_name, relation_arity in indexer.relations_arity.items():\n",
    "    relation_classifiers[relation_name] = torch.nn.Sequential(\n",
    "        torch.nn.Linear(emb_size, emb_size),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(emb_size, 1),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n",
    "reasoner = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_concepts, emb_size),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(emb_size, n_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "model = torch.nn.Sequential(encoder, *relation_classifiers.values(), reasoner)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce79a2d-d41e-4805-888d-d2f1def2f05c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5cb5debc-063e-446e-9224-bce2244c05f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 16])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.tensors[0].squeeze(0)\n",
    "embeddings = encoder(X)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5f1e5a12-9aec-4a1c-a44d-2085fe7f3e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18956, 1]),\n",
       " tensor([[0.5043],\n",
       "         [0.4720],\n",
       "         [0.4785],\n",
       "         ...,\n",
       "         [0.4782],\n",
       "         [0.4772],\n",
       "         [0.4793]], grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relation/concept predictions\n",
    "concept_predictions = indexer.predict_relations(encoders=relation_classifiers, embeddings=embeddings)\n",
    "concept_predictions.shape, concept_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c028d9ea-56c8-4c2b-84c0-a772029f8848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([980, 1]),\n",
       " tensor([[0.5043],\n",
       "         [0.4648],\n",
       "         [0.5644],\n",
       "         [0.4980],\n",
       "         [0.5405],\n",
       "         [0.5061],\n",
       "         [0.4710],\n",
       "         [0.4720],\n",
       "         [0.4271],\n",
       "         [0.5483]], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_preds = indexer.gather_and_concatenate(concept_predictions, indexer.indexed_queries[\"concepts\"], 0)\n",
    "c_preds.shape, c_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7bcaf980-7830-4450-bb90-6ce47ab0470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([980, 1]),\n",
       " tensor([[0.5043],\n",
       "         [0.4648],\n",
       "         [0.5644],\n",
       "         [0.4980],\n",
       "         [0.5405],\n",
       "         [0.5061],\n",
       "         [0.4710],\n",
       "         [0.4720],\n",
       "         [0.4271],\n",
       "         [0.5483]], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = indexer.gather_and_concatenate(concept_predictions, indexer.indexed_queries[\"tasks\"], 0)\n",
    "y_preds.shape, y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278c06c-64e9-4f3d-96ca-c4e152e4e51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
